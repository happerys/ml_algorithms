{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Naive Bayes Algorithm\n",
    "============\n",
    "\n",
    "> 朴素贝叶斯算法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对于给定的输入$X$，利用贝叶斯定理求出后验概率最大的输出$y$.\n",
    "\n",
    "> 设输入空间 $\\cal X \\subseteq R^n$ 为$n$维向量的集合，输出空间为类标记集合 $\\cal Y=\\{c_1, c_2, \\cdots , c_k\\}$ ，输入为特征向量 $x \\in \\cal X$，输出为类标记(class label)$y \\in \\cal Y$. $X$是定义在输入空间$\\cal X$上的随机向量，$Y$是定义在输出空间$\\cal Y$上的随机变量. $P(X,Y)$是$X$和$Y$的联合概率分布. 训练数据集$$T=\\{(x_1, y_1),(x_2, y_2),\\cdots,(x_k, y_k)\\}$$由$P(X,Y)$独立同分布产生.\n",
    "\n",
    "> 朴素贝叶斯公式推导：\n",
    ">> 朴素贝叶斯分类时，对给定的输入 $x$，通过学习到的模型计算后验概率分布 $P(Y=c_k | X=x)$，** 将后验概率最大的类作为 $x$ 的类输出 **。\n",
    ">> 后验概率计算根据贝叶斯定理如下：\n",
    "$$P(Y=c_k|X=x) = \\frac{P(X=x|Y=c_k)P(Y=c_k)}{\\sum_{k} P(X=x|Y=c_k)P(Y=c_k)} \\qquad    (1)$$\n",
    ">> 朴素贝叶斯法对条件概率分布作了条件独立性假设.\n",
    "$$P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},\\cdots,X^{(n)}=x^{(n)}|Y=c_k)=\\prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k) \\qquad   (2)$$\n",
    ">> 把公式(2)代入公式(1)得到朴素贝叶斯分类的基本公式(3)：\n",
    "$$P(Y=c_k|X=x) = \\frac{P(Y=c_k)\\prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)}{\\sum_{k}P(Y=c_k)\\prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)},\\;k=1,2,3,\\cdots,K \\qquad    (3)$$\n",
    ">> 朴素贝叶斯分类器表示如下：\n",
    "$$y=f(x)=arg\\;{max}_{c_k}\\frac{P(Y=c_k)\\prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)}{\\sum_{k}P(Y=c_k)\\prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)}\\qquad   (4)$$\n",
    ">> 由于(4)中分母对所有的$c_k$都是相同的，所以，\n",
    "$$y=f(x)=arg\\;{max}_{c_k} P(Y=c_k)\\prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)\\qquad   (5)$$\n",
    "\n",
    "> 朴素贝叶斯算法:\n",
    ">> 输入：训练数据$T=\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)\\}$，其中$x_i={(x_i^{(1)},x_i^{(2)},\\cdots,x_i^{(n)})}^T$，$x_i^{(j)}$是第$i$个样本的第$j$个特征，$x_i^{(j)}\\in\\{{a_{j1},a_{j2},\\cdots,a_{jS_j}}\\}$，$a_{jl}$是第$j$个特征可能取得第l个值，$j=1,2,\\cdots,n,\\;l=1,2,\\cdots,S_j,\\;y_i\\in\\{c_1,c_2,\\cdots,c_K\\}$；实例$x$；\n",
    ">> 输出：实例$x$的分类.\n",
    "\n",
    ">> (1)计算先验概率及条件概率\n",
    "$$P(Y=c_k)=\\frac{\\sum_{i=1}^NI(y_i=c_k)}{N},\\;k=1,2,\\cdots,K$$\n",
    "$$P(X^{(j)}=a_{jl}|Y=c_k)=\\frac{\\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)}{\\sum_{i=1}^NI(y_i=c_k)}$$\n",
    "$$j=1,2,\\cdots,n;\\;l=1,2,\\cdots,S_j;\\;k=1,2,\\cdots,K$$\n",
    "\n",
    ">> (2)对于给定的实例$x={(x^{(1)},x^{(2)},\\cdots,x^{(n)})}^T$，计算\n",
    "$$P(Y=c_k)\\prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)\\;k=1,2,\\cdots,K$$\n",
    "\n",
    ">> (3)确定实例$x$的类\n",
    "$$y=arg\\;{max}_{c_k} P(Y=c_k)\\prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)$$\n",
    "\n",
    "> 拉普拉斯平滑\n",
    ">> 用极大似然估计可能会出现所要估计的概率值为0的情况。这时会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用**贝叶斯估计**。条件概率的贝叶斯估计是\n",
    "$$P_\\lambda(X^{(j)}=a_{jl}|Y=c_k)=\\frac{\\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)+\\lambda}{\\sum_{i=1}^NI(y_i=c_k)+S_j\\lambda}\\qquad(6)$$\n",
    ">> 式中$\\lambda\\geq0$.等价于在随机变量各个取值的频数上赋予一个正数$\\lambda>0$.当$\\lambda=0$时就是极大似然估计.取$\\lambda=1$，这时称为拉普拉斯平滑(Laplace smoothing).显然，对任何$l=1,2,\\cdots,K$，有\n",
    "$$P_\\lambda(X^{(j)}=a_{jl}|Y=c_k)>0$$\n",
    "$$\\sum_{k}^{S_j} P(X^{(j)}=a_{jl}|Y=c_k)=1$$\n",
    ">> 先验概率的贝叶斯估计是\n",
    "$$P_\\lambda(Y=c_k)=\\frac{\\sum_{i=1}^NI(y_i=c_k)+\\lambda}{N+K\\lambda}$$\n",
    "\n",
    "> ***备注：参考资料《统计学习方法》，李航 著***\n",
    "\n",
    "> 贝叶斯算法的优缺点：\n",
    ">> 优点：在数据较少的情况下仍然有效，可以处理多类别问题；\n",
    "\n",
    ">> 缺点：对于输入数据的准备方式较为敏感；\n",
    "\n",
    ">> 适用数据类型：标称型数据.\n",
    "\n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取语料\n",
    "def textParse(bigString):\n",
    "    import re\n",
    "    listOfTokens = re.split(r'\\W*', bigString)\n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 2]\n",
    "\n",
    "# 创建一个包含所有文档中出现的不重复词的列表\n",
    "def createVocabList(dataSet ): \n",
    "    vocabSet = set ([])\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document) \n",
    "    # print vocabSet\n",
    "    return list(vocabSet)\n",
    "\n",
    "# （词袋模型）输入词汇表及某个文档，输出文档向量，向量的每个元素为1或0，分别表示词汇中的单词再输入文档中是否出现\n",
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    returnVec = [0]*len(vocabList) \n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "        else: \n",
    "            print \"the word：%s is not in my Vocabulary!\" % word \n",
    "    return returnVec\n",
    "\n",
    "def spamTest():\n",
    "    import random\n",
    "    docList = []; classList = []; fullText = []\n",
    "    for i in range(1, 26):\n",
    "        wordList = textParse(open('/Users/zhangxingbin/ml_algorithms/data/email/spam/%d.txt' % i).read())\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        classList.append(1)\n",
    "        wordList = textParse(open('/Users/zhangxingbin/ml_algorithms/data/email/ham/%d.txt' % i).read())\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        classList.append(0)\n",
    "    vocabList = createVocabList(docList)\n",
    "    trainingSet = range(50); testSet=[]\n",
    "    for i in range(10):\n",
    "        randIndex = int(random.uniform(0, len(trainingSet)))\n",
    "        testSet.append(trainingSet[randIndex])\n",
    "        del(trainingSet[randIndex])\n",
    "    trainMat = []; trainClasses = []\n",
    "    for docIndex in trainingSet:\n",
    "        trainMat.append(setOfWords2Vec(vocabList, docList[docIndex]))\n",
    "        trainClasses.append(classList[docIndex])\n",
    "\n",
    "    return trainMat, trainClasses, testSet\n",
    "#     print vocabList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spamTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train(trainMatrix, trainCategory):\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    numWords = len(trainMatrix[0])\n",
    "    pAbusive = sum(trainCategory) / float(numTrainDocs)   # \n",
    "    \n",
    "    pONum = zeros (numWords); \n",
    "    plNum = zeros (numWords)\n",
    "    pODenom = 0.0; \n",
    "    plDenom = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多项式模型\n",
    "--------\n",
    "> 文档$d$属于类别$c$的概率\n",
    "$$P(c|d)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
